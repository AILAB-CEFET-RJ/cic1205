{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a8a1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence:\n",
      " tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986],\n",
      "        [ 0.4033,  0.8380, -0.7193],\n",
      "        [-0.4033, -0.5966,  0.1820]])\n",
      "\n",
      "Output at each time step:\n",
      " tensor([[-0.1491,  0.0378],\n",
      "        [-0.2774,  0.0892],\n",
      "        [-0.0008,  0.2280],\n",
      "        [ 0.0942,  0.1251]], grad_fn=<SqueezeBackward0>)\n",
      "\n",
      "Final hidden state:\n",
      " tensor([0.0942, 0.1251], grad_fn=<SqueezeBackward0>)\n",
      "\n",
      "Final cell state:\n",
      " tensor([0.2080, 0.3955], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Input dimensions\n",
    "seq_len = 4      # number of time steps\n",
    "input_dim = 3    # features per time step\n",
    "hidden_dim = 2   # LSTM hidden state size\n",
    "batch_size = 1   # for simplicity\n",
    "\n",
    "# Dummy input (sequence of vectors)\n",
    "x = torch.randn(batch_size, seq_len, input_dim)\n",
    "\n",
    "# Define LSTM layer (1 layer, unidirectional)\n",
    "lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "# Initial hidden and cell states (h0, c0)\n",
    "h0 = torch.zeros(1, batch_size, hidden_dim)\n",
    "c0 = torch.zeros(1, batch_size, hidden_dim)\n",
    "\n",
    "# Forward pass\n",
    "output, (hn, cn) = lstm(x, (h0, c0))\n",
    "\n",
    "# Print outputs\n",
    "print(\"Input sequence:\\n\", x.squeeze())\n",
    "print(\"\\nOutput at each time step:\\n\", output.squeeze())\n",
    "print(\"\\nFinal hidden state:\\n\", hn.squeeze())\n",
    "print(\"\\nFinal cell state:\\n\", cn.squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62bdb45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 5])\n",
      "Output shape (all time steps): torch.Size([2, 4, 8])\n",
      "Final hidden state shape: torch.Size([1, 2, 8])\n",
      "Final cell state shape: torch.Size([1, 2, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Config\n",
    "input_size = 5     # number of features per time step\n",
    "hidden_size = 8    # size of hidden state and cell state\n",
    "seq_len = 4        # length of the input sequence\n",
    "batch_size = 2     # number of sequences in a batch\n",
    "\n",
    "# Dummy input: shape = (batch_size, seq_len, input_size)\n",
    "x = torch.randn(batch_size, seq_len, input_size)\n",
    "\n",
    "# Define LSTM layer\n",
    "lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "\n",
    "# Initial hidden state and cell state (num_layers=1 by default)\n",
    "h0 = torch.zeros(1, batch_size, hidden_size)  # shape: (num_layers, batch_size, hidden_size)\n",
    "c0 = torch.zeros(1, batch_size, hidden_size)\n",
    "\n",
    "# Forward pass\n",
    "output, (hn, cn) = lstm(x, (h0, c0))\n",
    "\n",
    "# Print shapes\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape (all time steps):\", output.shape)\n",
    "print(\"Final hidden state shape:\", hn.shape)\n",
    "print(\"Final cell state shape:\", cn.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cic1205",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
