{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Normalization Equations\n",
    "\n",
    "Layer Normalization is a technique used to normalize the activations of a neural network layer across the features for each individual data sample. Layer Normalization normalizes the activations across features for each data sample independently. The mean and variance are computed per sample and per feature, ensuring that each feature has zero mean and unit variance. The normalized output is then scaled and shifted using learnable parameters, allowing the network to maintain expressiveness while stabilizing the training process.\n",
    "\n",
    "The key equations used in Layer Normalization are as follows:\n",
    "\n",
    "## 1. Mean Calculation\n",
    "\n",
    "For a given layer with input features $x_i$, the mean $\\mu$ of the features is computed as:\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{1}{H} \\sum_{i=1}^{H} x_i\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $H$ is the number of features in the layer.\n",
    "- $x_i$ is the $i$-th feature of the input.\n",
    "\n",
    "## 2. Variance Calculation\n",
    "\n",
    "The variance $\\sigma^2$ of the features is calculated as:\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{1}{H} \\sum_{i=1}^{H} (x_i - \\mu)^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\sigma^2$ is the variance of the features.\n",
    "\n",
    "## 3. Normalization\n",
    "\n",
    "The normalized output $\\hat{x}_i$ for each feature $x_i$ is given by:\n",
    "\n",
    "$$\n",
    "\\hat{x}_i = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\mu$ is the mean of the features.\n",
    "- $\\sigma^2$ is the variance of the features.\n",
    "- $\\epsilon$ is a small constant added for numerical stability (e.g., $\\epsilon = 1 \\times 10^{-5}$).\n",
    "\n",
    "## 4. Scaling and Shifting\n",
    "\n",
    "After normalization, the output is scaled and shifted using learnable parameters $\\gamma$ and $\\beta$:\n",
    "\n",
    "$$\n",
    "y_i = \\gamma \\hat{x}_i + \\beta\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\gamma$ is the scale parameter.\n",
    "- $\\beta$ is the shift parameter.\n",
    "- $\\hat{x}_i$ is the normalized feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LayerNorm\n",
    "\n",
    "The `LayerNorm` (Layer Normalization) class in PyTorch is used to normalize the inputs across the features within each example in a batch. This normalization helps stabilize and accelerate the training process by reducing internal covariate shift, which is the change in the distribution of layer inputs during training. LayerNorm helps ensure that each layer's output has a stable distribution during training. This makes the learning process more efficient and reduces the chances of the network getting stuck in suboptimal regions of the loss landscape.\n",
    "\n",
    "Benefits of using Layer Normalization:\n",
    "- Stabilizes Training: By normalizing the activations, LayerNorm helps reduce fluctuations in the gradient during backpropagation, leading to more stable and faster convergence.\n",
    "- Independence from Batch Size: Unlike Batch Normalization, which normalizes across a batch of examples, LayerNorm normalizes each example independently. This makes it particularly useful when training with very small batch sizes or even with a single example (e.g., in online learning).\n",
    "\n",
    "How LayerNorm Works:\n",
    "- Normalization: For each individual example in the batch, LayerNorm computes the mean and variance across all features (i.e., across the specified dimension). The layer then normalizes the input by subtracting the mean and dividing by the standard deviation.\n",
    "- Learnable Parameters: Unlike standard normalization techniques (like Batch Normalization), LayerNorm does not depend on the batch size. It has learnable parameters (a scale $\\gamma$ and a shift $\\beta$) that allow the network to restore some of the representational power that might be lost during normalization. These parameters are learned during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 16)  # input shape (1,10) means 10 features\n",
    "        self.norm1 = nn.LayerNorm(16)\n",
    "        self.fc2 = nn.Linear(16, 10)\n",
    "        self.norm2 = nn.LayerNorm(10)\n",
    "        self.fc3 = nn.Linear(10, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.norm1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.norm2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cic1205",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
