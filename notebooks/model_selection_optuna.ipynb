{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#005097; border:0' role=\"tab\" aria-controls=\"home\"><center>Hyperparameter Optimization with Optuna</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna is an open-source hyperparameter optimization framework that automates the process of tuning machine learning models by efficiently searching for the best hyperparameters. It supports both classical machine learning models and deep learning models, and its goal is to maximize or minimize a given **objective function**, such as model performance, by optimizing hyperparameters.\n",
    "\n",
    "In the Optuna optimization framework, a **study** is the main object that represents an optimization session. It encompasses the entire optimization process — including the definition of the objective function, the trials (each set of hyperparameters tested), and the history and results of those trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna selects the **sampling strategy** based on the **study configuration** and **hyperparameter types**. The choice depends on the search space, the number of trials, and whether prior knowledge is available.\n",
    "\n",
    "## 1️⃣ Default Strategy: Tree-structured Parzen Estimator (TPE)\n",
    "- If no specific sampler is specified, Optuna **automatically** uses **TPE (Tree-structured Parzen Estimator)**.\n",
    "- TPE **models the probability distribution** of good and bad hyperparameter choices and chooses new trials accordingly.\n",
    "- Best for **non-convex search spaces** where grid/random search fails.\n",
    "\n",
    "Example of instantiating a study that uses TPE:\n",
    "\n",
    "```python\n",
    "import optuna\n",
    "study = optuna.create_study(direction=\"maximize\")  # Uses TPE by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ Explicitly Specifying a Sampler\n",
    "You can override the default and choose a specific sampler:\n",
    "\n",
    "| Sampler                  | When to Use?                                           | Example                                      |\n",
    "|--------------------------|------------------------------------------------------|----------------------------------------------|\n",
    "| **TPE (default)**        | Works well in most cases, adaptive Bayesian optimization | `optuna.samplers.TPESampler()`               |\n",
    "| **Random Search**        | Good for benchmarking, large search spaces          | `optuna.samplers.RandomSampler()`           |\n",
    "| **Grid Search**          | If you have limited trials and want exhaustive search | `optuna.samplers.GridSampler(search_space)` |\n",
    "| **CMA-ES**              | Good for continuous spaces, often used in reinforcement learning | `optuna.samplers.CmaEsSampler()` |\n",
    "\n",
    "Example of choosing a sampler:\n",
    "\n",
    "```python\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.RandomSampler()  # Choose random search\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ How Optuna Adapts to the Problem\n",
    "Optuna adjusts the search strategy based on:\n",
    "\n",
    "- Discrete vs. Continuous Parameters. If parameters are categorical (trial.suggest_categorical), TPE handles them well. If parameters are continuous (trial.suggest_float), CMA-ES or TPE works better.\n",
    "- Log-scaled vs. Linear Search Space. If log=True is used (e.g., learning_rate), Optuna adjusts the sampling distribution accordingly.\n",
    "- Early Pruning and Convergence. If trials are pruned early, TPE focuses on exploiting promising areas rather than random exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ Customizing the Sampling Strategy\n",
    "You can combine samplers or switch strategies mid-experiment:\n",
    "\n",
    "```python\n",
    "sampler = optuna.samplers.TPESampler(n_startup_trials=10)  # Use random search for first 10 trials\n",
    "study = optuna.create_study(sampler=sampler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/aug_train.csv')\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop(columns=['id', 'Response'])\n",
    "y = data['Response']\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['Gender', 'Vehicle_Age', 'Vehicle_Damage']\n",
    "numerical_features = X.columns.difference(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-10 05:27:13,275] A new study created in memory with name: no-name-74b16ce9-45fa-4e35-ace1-193434f61b06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-10 05:27:26,358] Trial 0 finished with value: 0.3414115867516296 and parameters: {'n_estimators': 69, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.3414115867516296.\n",
      "[I 2025-04-10 05:27:58,037] Trial 1 finished with value: 0.00027945307348764586 and parameters: {'n_estimators': 239, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.3414115867516296.\n",
      "[I 2025-04-10 05:28:30,901] Trial 2 finished with value: 0.27134730746322805 and parameters: {'n_estimators': 191, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.3414115867516296.\n",
      "[I 2025-04-10 05:29:12,136] Trial 3 finished with value: 0.06669601151876058 and parameters: {'n_estimators': 285, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.3414115867516296.\n",
      "[I 2025-04-10 05:29:55,640] Trial 4 finished with value: 0.07699580221032808 and parameters: {'n_estimators': 295, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.3414115867516296.\n",
      "[I 2025-04-10 05:30:11,876] Trial 5 finished with value: 0.29978941584161434 and parameters: {'n_estimators': 78, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.3414115867516296.\n",
      "[I 2025-04-10 05:30:35,740] Trial 6 finished with value: 0.027620524825490492 and parameters: {'n_estimators': 185, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.3414115867516296.\n",
      "[I 2025-04-10 05:30:51,978] Trial 7 finished with value: 0.0 and parameters: {'n_estimators': 136, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.3414115867516296.\n",
      "[I 2025-04-10 05:31:28,946] Trial 8 finished with value: 0.09759159330955391 and parameters: {'n_estimators': 240, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.3414115867516296.\n",
      "[I 2025-04-10 05:31:43,134] Trial 9 finished with value: 0.0018708469474963475 and parameters: {'n_estimators': 118, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.3414115867516296.\n",
      "[I 2025-04-10 05:32:01,149] A new study created in memory with name: no-name-c8ba26b2-0872-4ca6-96e0-cd45f39be0a0\n",
      "[I 2025-04-10 05:32:29,150] Trial 0 finished with value: 0.33587881542257625 and parameters: {'n_estimators': 151, 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.33587881542257625.\n",
      "[I 2025-04-10 05:33:15,780] Trial 1 finished with value: 0.3731010723961914 and parameters: {'n_estimators': 253, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.3731010723961914.\n",
      "[I 2025-04-10 05:33:56,030] Trial 2 finished with value: 0.1079761693631978 and parameters: {'n_estimators': 262, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.3731010723961914.\n",
      "[I 2025-04-10 05:34:34,606] Trial 3 finished with value: 0.32961123664312475 and parameters: {'n_estimators': 217, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.3731010723961914.\n",
      "[I 2025-04-10 05:35:03,212] Trial 4 finished with value: 0.34316103355495836 and parameters: {'n_estimators': 156, 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.3731010723961914.\n",
      "[I 2025-04-10 05:35:42,207] Trial 5 finished with value: 0.40691059414949987 and parameters: {'n_estimators': 198, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.40691059414949987.\n",
      "[I 2025-04-10 05:36:28,749] Trial 6 finished with value: 0.31242671749634304 and parameters: {'n_estimators': 269, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 5 with value: 0.40691059414949987.\n",
      "[I 2025-04-10 05:36:46,831] Trial 7 finished with value: 0.0 and parameters: {'n_estimators': 177, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.40691059414949987.\n",
      "[I 2025-04-10 05:37:01,479] Trial 8 finished with value: 0.17134656404530588 and parameters: {'n_estimators': 93, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 5 with value: 0.40691059414949987.\n",
      "[I 2025-04-10 05:37:35,237] Trial 9 finished with value: 0.08689771773788123 and parameters: {'n_estimators': 234, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 5 with value: 0.40691059414949987.\n",
      "[I 2025-04-10 05:38:30,646] A new study created in memory with name: no-name-37b9b0fa-e347-4927-9603-8e320f8d3ea9\n",
      "[I 2025-04-10 05:38:57,535] Trial 0 finished with value: 0.0 and parameters: {'n_estimators': 292, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-04-10 05:39:09,097] Trial 1 finished with value: 0.407406237168574 and parameters: {'n_estimators': 62, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.407406237168574.\n",
      "[I 2025-04-10 05:39:47,823] Trial 2 finished with value: 0.10090574770101512 and parameters: {'n_estimators': 257, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.407406237168574.\n",
      "[I 2025-04-10 05:39:58,755] Trial 3 finished with value: 0.3963361655215408 and parameters: {'n_estimators': 59, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.407406237168574.\n",
      "[I 2025-04-10 05:40:44,319] Trial 4 finished with value: 0.36411448734911306 and parameters: {'n_estimators': 238, 'max_depth': 17, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.407406237168574.\n",
      "[I 2025-04-10 05:41:30,394] Trial 5 finished with value: 0.3982403295845239 and parameters: {'n_estimators': 249, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.407406237168574.\n",
      "[I 2025-04-10 05:42:13,284] Trial 6 finished with value: 0.1518176083059646 and parameters: {'n_estimators': 273, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.407406237168574.\n",
      "[I 2025-04-10 05:42:35,335] Trial 7 finished with value: 0.3821898677186142 and parameters: {'n_estimators': 112, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.407406237168574.\n",
      "[I 2025-04-10 05:43:16,039] Trial 8 finished with value: 0.33875864723788696 and parameters: {'n_estimators': 240, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.407406237168574.\n",
      "[I 2025-04-10 05:43:50,235] Trial 9 finished with value: 0.11672949904718517 and parameters: {'n_estimators': 210, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.407406237168574.\n",
      "[I 2025-04-10 05:44:05,179] A new study created in memory with name: no-name-92e62d08-b9a4-4689-86ff-3a05215380e1\n",
      "[I 2025-04-10 05:44:52,305] Trial 0 finished with value: 0.10220013849135696 and parameters: {'n_estimators': 291, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.10220013849135696.\n",
      "[I 2025-04-10 05:45:37,762] Trial 1 finished with value: 0.34705540511991756 and parameters: {'n_estimators': 249, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.34705540511991756.\n",
      "[I 2025-04-10 05:46:13,271] Trial 2 finished with value: 0.23409855082864073 and parameters: {'n_estimators': 204, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.34705540511991756.\n",
      "[I 2025-04-10 05:46:41,792] Trial 3 finished with value: 0.32777329994976484 and parameters: {'n_estimators': 155, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.34705540511991756.\n",
      "[I 2025-04-10 05:47:24,489] Trial 4 finished with value: 0.3816542109383128 and parameters: {'n_estimators': 233, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 4 with value: 0.3816542109383128.\n",
      "[I 2025-04-10 05:48:12,926] Trial 5 finished with value: 0.38941843334286935 and parameters: {'n_estimators': 263, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 5 with value: 0.38941843334286935.\n",
      "[I 2025-04-10 05:48:58,898] Trial 6 finished with value: 0.2982272565499166 and parameters: {'n_estimators': 255, 'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 5 with value: 0.38941843334286935.\n",
      "[I 2025-04-10 05:49:15,310] Trial 7 finished with value: 0.0 and parameters: {'n_estimators': 252, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 5 with value: 0.38941843334286935.\n",
      "[I 2025-04-10 05:49:39,448] Trial 8 finished with value: 0.0 and parameters: {'n_estimators': 270, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.38941843334286935.\n",
      "[I 2025-04-10 05:50:06,033] Trial 9 finished with value: 0.09125152015696852 and parameters: {'n_estimators': 178, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.38941843334286935.\n",
      "[I 2025-04-10 05:51:07,421] A new study created in memory with name: no-name-3be9ecc4-e48a-48a5-9199-749e583763f6\n",
      "[I 2025-04-10 05:51:18,993] Trial 0 finished with value: 0.07329519960783262 and parameters: {'n_estimators': 64, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.07329519960783262.\n",
      "[I 2025-04-10 05:51:39,037] Trial 1 finished with value: 0.00019963427156395654 and parameters: {'n_estimators': 173, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.07329519960783262.\n",
      "[I 2025-04-10 05:52:11,057] Trial 2 finished with value: 0.12415258861293638 and parameters: {'n_estimators': 199, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.12415258861293638.\n",
      "[I 2025-04-10 05:53:04,923] Trial 3 finished with value: 0.4068149924839147 and parameters: {'n_estimators': 270, 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.4068149924839147.\n",
      "[I 2025-04-10 05:53:19,362] Trial 4 finished with value: 0.0 and parameters: {'n_estimators': 175, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.4068149924839147.\n",
      "[I 2025-04-10 05:53:37,876] Trial 5 finished with value: 0.37862898218399527 and parameters: {'n_estimators': 91, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.4068149924839147.\n",
      "[I 2025-04-10 05:54:15,820] Trial 6 finished with value: 0.19519135313925082 and parameters: {'n_estimators': 237, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.4068149924839147.\n",
      "[I 2025-04-10 05:55:06,938] Trial 7 finished with value: 0.37358486615686354 and parameters: {'n_estimators': 288, 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.4068149924839147.\n",
      "[I 2025-04-10 05:55:36,097] Trial 8 finished with value: 0.4165561459937632 and parameters: {'n_estimators': 143, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 8 with value: 0.4165561459937632.\n",
      "[I 2025-04-10 05:56:11,635] Trial 9 finished with value: 0.20359520434902412 and parameters: {'n_estimators': 218, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.4165561459937632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV F1 scores: [0.33155859440677016, 0.414046590175334, 0.4091045823724055, 0.3943604413567634, 0.4289385637395141]\n",
      "Mean F1 score: 0.39560175441015744\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import optuna\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_features),\n",
    "    ('cat', OneHotEncoder(), categorical_features)\n",
    "])\n",
    "\n",
    "N_TRIALS = 10\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "outer_scores = []\n",
    "\n",
    "for train_idx, test_idx in outer_cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    def objective(trial):\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "\n",
    "        model = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                min_samples_split=min_samples_split,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=inner_cv, scoring='f1', n_jobs=-1)\n",
    "        return np.mean(scores)\n",
    "\n",
    "    # Run Optuna for current outer fold\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "    # Train model with best params on full inner training set\n",
    "    best_params = study.best_params\n",
    "    final_model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(**best_params, random_state=42))\n",
    "    ])\n",
    "    final_model.fit(X_train, y_train)\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    outer_scores.append(score)\n",
    "\n",
    "print(\"Nested CV F1 scores:\", outer_scores)\n",
    "print(\"Mean F1 score:\", np.mean(outer_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on test set: 0.4440074991997805\n",
      "CPU times: user 48.3 s, sys: 75 ms, total: 48.4 s\n",
      "Wall time: 47.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Train final model with best hyperparameters\n",
    "best_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        # max_depth=best_params['max_depth'],\n",
    "        min_samples_split=best_params['min_samples_split'],\n",
    "        min_samples_leaf=best_params['min_samples_leaf'],\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train and evaluate the model\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1-score on test set:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on test set: 0.43990114580993034\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "default_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "default_model.fit(X_train, y_train)\n",
    "y_pred = default_model.predict(X_test)\n",
    "# Evaluate performance\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1-score on test set:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cic1205",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
